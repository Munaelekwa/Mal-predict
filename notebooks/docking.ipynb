{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (318967, 2048)\n",
      "Target matrix shape: (318967, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# File paths - replace with your actual file paths\n",
    "compound_files = [\n",
    "    '../data/docking_results/Final_Dataset_DB.csv',\n",
    "    '../data/docking_results/Final_Dataset_EN.csv',\n",
    "    '../data/docking_results/Final_Dataset_NP.csv'\n",
    "]\n",
    "\n",
    "docking_files = [\n",
    "    '../data/docking_results/3ebh.csv',\n",
    "    '../data/docking_results/3i65.csv',\n",
    "    '../data/docking_results/8em8.csv',\n",
    "    '../data/docking_results/9nsr.csv'\n",
    "]\n",
    "\n",
    "def load_compounds(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    compounds = pd.concat(dfs, ignore_index=True)\n",
    "    return compounds[['ID', 'smiles']]\n",
    "\n",
    "def load_and_merge_docking(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        protein_code = os.path.splitext(os.path.basename(file))[0]\n",
    "        df = pd.read_csv(file)\n",
    "        df['ID'] = df['ID'].str.removeprefix('lig_')\n",
    "        df['ID'] = df['ID'].str.removesuffix('.pdbqt')\n",
    "        df = df[['ID', 'Binding_Affinity']]\n",
    "        df = df.rename(columns={'Binding_Affinity': f'Binding_Affinity_{protein_code}'})\n",
    "        dfs.append(df)\n",
    "    # Merge docking results on compound_id\n",
    "    docking_merged = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        docking_merged = docking_merged.merge(df, on='ID', how='inner')\n",
    "    return docking_merged\n",
    "\n",
    "morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def smiles_to_fingerprint(smiles):\n",
    "    if not isinstance(smiles, str):\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = morgan_gen.GetFingerprint(mol)\n",
    "    arr = np.zeros((2048,), dtype=int)\n",
    "    fp.ToBitString()  # optional, just to check\n",
    "    # Convert to numpy array\n",
    "    from rdkit.DataStructs import ConvertToNumpyArray\n",
    "    ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "# Load compounds\n",
    "compounds = load_compounds(compound_files)\n",
    "\n",
    "# Load and merge docking scores\n",
    "docking_scores = load_and_merge_docking(docking_files)\n",
    "\n",
    "# Merge compounds and docking on compound_id\n",
    "df = compounds.merge(docking_scores, on='ID', how='inner')\n",
    "\n",
    "# Convert SMILES to fingerprints\n",
    "fingerprints = []\n",
    "for smi in df['smiles']:\n",
    "    fp = smiles_to_fingerprint(smi)\n",
    "    if fp is None:\n",
    "        # Handle invalid SMILES by skipping or imputing zero vector\n",
    "        fp = np.zeros(2048, dtype=int)\n",
    "    fingerprints.append(fp)\n",
    "fingerprints = np.array(fingerprints)\n",
    "\n",
    "# Prepare features (X) and targets (y)\n",
    "X = fingerprints\n",
    "protein_codes = ['3ebh', '3i65', '8em8', '9nsr']  \n",
    "y = df[[f'Binding_Affinity_{code}' for code in protein_codes]].values.astype(float)\n",
    "\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target matrix shape:\", y.shape)\n",
    "\n",
    "# Save or return processed arrays as needed for model training\n",
    "# For example, save as numpy files:\n",
    "np.save('../data/docking_results/X_features.npy', X)\n",
    "np.save('../data/docking_results/y_docking_scores.npy', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 30ms/step - loss: 0.8812 - mse: 0.8812 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 2/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 27ms/step - loss: 0.5016 - mse: 0.5016 - val_loss: 0.4987 - val_mse: 0.4987\n",
      "Epoch 3/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 18ms/step - loss: 0.4905 - mse: 0.4905 - val_loss: 0.4972 - val_mse: 0.4972\n",
      "Epoch 4/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 15ms/step - loss: 0.4833 - mse: 0.4833 - val_loss: 0.5037 - val_mse: 0.5037\n",
      "Epoch 5/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 11ms/step - loss: 0.4775 - mse: 0.4775 - val_loss: 0.5361 - val_mse: 0.5361\n",
      "Epoch 6/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 19ms/step - loss: 0.4713 - mse: 0.4713 - val_loss: 0.4947 - val_mse: 0.4947\n",
      "Epoch 7/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 18ms/step - loss: 0.4663 - mse: 0.4663 - val_loss: 0.5028 - val_mse: 0.5028\n",
      "Epoch 8/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 18ms/step - loss: 0.4619 - mse: 0.4619 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 9/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 12ms/step - loss: 0.4582 - mse: 0.4582 - val_loss: 0.5074 - val_mse: 0.5074\n",
      "Epoch 10/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 15ms/step - loss: 0.4547 - mse: 0.4547 - val_loss: 0.5048 - val_mse: 0.5048\n",
      "Epoch 11/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 20ms/step - loss: 0.4518 - mse: 0.4518 - val_loss: 0.5039 - val_mse: 0.5039\n",
      "Epoch 12/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 11ms/step - loss: 0.4491 - mse: 0.4491 - val_loss: 0.5036 - val_mse: 0.5036\n",
      "Epoch 13/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 9ms/step - loss: 0.4467 - mse: 0.4467 - val_loss: 0.5102 - val_mse: 0.5102\n",
      "Epoch 14/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 9ms/step - loss: 0.4446 - mse: 0.4446 - val_loss: 0.5078 - val_mse: 0.5078\n",
      "Epoch 15/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 10ms/step - loss: 0.4427 - mse: 0.4427 - val_loss: 0.5119 - val_mse: 0.5119\n",
      "Epoch 16/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 13ms/step - loss: 0.4408 - mse: 0.4408 - val_loss: 0.5116 - val_mse: 0.5116\n",
      "Epoch 17/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 13ms/step - loss: 0.4395 - mse: 0.4395 - val_loss: 0.5194 - val_mse: 0.5194\n",
      "Epoch 18/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 12ms/step - loss: 0.4379 - mse: 0.4379 - val_loss: 0.5099 - val_mse: 0.5099\n",
      "Epoch 19/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 18ms/step - loss: 0.4368 - mse: 0.4368 - val_loss: 0.5239 - val_mse: 0.5239\n",
      "Epoch 20/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 22ms/step - loss: 0.4352 - mse: 0.4352 - val_loss: 0.5179 - val_mse: 0.5179\n",
      "Epoch 21/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 13ms/step - loss: 0.4343 - mse: 0.4343 - val_loss: 0.5219 - val_mse: 0.5219\n",
      "Epoch 22/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2141s\u001b[0m 268ms/step - loss: 0.4330 - mse: 0.4330 - val_loss: 0.5242 - val_mse: 0.5242\n",
      "Epoch 23/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m856s\u001b[0m 107ms/step - loss: 0.4321 - mse: 0.4321 - val_loss: 0.5186 - val_mse: 0.5186\n",
      "Epoch 24/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 39ms/step - loss: 0.4314 - mse: 0.4314 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 25/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 30ms/step - loss: 0.4302 - mse: 0.4302 - val_loss: 0.5172 - val_mse: 0.5172\n",
      "Epoch 26/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 19ms/step - loss: 0.4293 - mse: 0.4293 - val_loss: 0.5229 - val_mse: 0.5229\n",
      "Epoch 27/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 0.4286 - mse: 0.4286 - val_loss: 0.5174 - val_mse: 0.5174\n",
      "Epoch 28/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 10ms/step - loss: 0.4277 - mse: 0.4277 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 29/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 19ms/step - loss: 0.4270 - mse: 0.4270 - val_loss: 0.5187 - val_mse: 0.5187\n",
      "Epoch 30/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 18ms/step - loss: 0.4265 - mse: 0.4265 - val_loss: 0.5204 - val_mse: 0.5204\n",
      "Epoch 31/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 21ms/step - loss: 0.4258 - mse: 0.4258 - val_loss: 0.5239 - val_mse: 0.5239\n",
      "Epoch 32/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 16ms/step - loss: 0.4248 - mse: 0.4248 - val_loss: 0.5231 - val_mse: 0.5231\n",
      "Epoch 33/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 10ms/step - loss: 0.4243 - mse: 0.4243 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 34/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 11ms/step - loss: 0.4237 - mse: 0.4237 - val_loss: 0.5257 - val_mse: 0.5257\n",
      "Epoch 35/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 10ms/step - loss: 0.4231 - mse: 0.4231 - val_loss: 0.5237 - val_mse: 0.5237\n",
      "Epoch 36/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 12ms/step - loss: 0.4227 - mse: 0.4227 - val_loss: 0.5266 - val_mse: 0.5266\n",
      "Epoch 37/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 11ms/step - loss: 0.4225 - mse: 0.4225 - val_loss: 0.5225 - val_mse: 0.5225\n",
      "Epoch 38/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 31ms/step - loss: 0.4218 - mse: 0.4218 - val_loss: 0.5294 - val_mse: 0.5294\n",
      "Epoch 39/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 23ms/step - loss: 0.4211 - mse: 0.4211 - val_loss: 0.5352 - val_mse: 0.5352\n",
      "Epoch 40/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 27ms/step - loss: 0.4206 - mse: 0.4206 - val_loss: 0.5291 - val_mse: 0.5291\n",
      "Epoch 41/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 14ms/step - loss: 0.4202 - mse: 0.4202 - val_loss: 0.5282 - val_mse: 0.5282\n",
      "Epoch 42/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 20ms/step - loss: 0.4199 - mse: 0.4199 - val_loss: 0.5327 - val_mse: 0.5327\n",
      "Epoch 43/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 14ms/step - loss: 0.4194 - mse: 0.4194 - val_loss: 0.5263 - val_mse: 0.5263\n",
      "Epoch 44/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 24ms/step - loss: 0.4190 - mse: 0.4190 - val_loss: 0.5275 - val_mse: 0.5275\n",
      "Epoch 45/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 17ms/step - loss: 0.4188 - mse: 0.4188 - val_loss: 0.5262 - val_mse: 0.5262\n",
      "Epoch 46/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 20ms/step - loss: 0.4181 - mse: 0.4181 - val_loss: 0.5293 - val_mse: 0.5293\n",
      "Epoch 47/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 24ms/step - loss: 0.4178 - mse: 0.4178 - val_loss: 0.5358 - val_mse: 0.5358\n",
      "Epoch 48/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 19ms/step - loss: 0.4175 - mse: 0.4175 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 49/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 13ms/step - loss: 0.4175 - mse: 0.4175 - val_loss: 0.5349 - val_mse: 0.5349\n",
      "Epoch 50/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 28ms/step - loss: 0.4169 - mse: 0.4169 - val_loss: 0.5315 - val_mse: 0.5315\n",
      "Epoch 51/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 24ms/step - loss: 0.4165 - mse: 0.4165 - val_loss: 0.5336 - val_mse: 0.5336\n",
      "Epoch 52/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 26ms/step - loss: 0.4163 - mse: 0.4163 - val_loss: 0.5329 - val_mse: 0.5329\n",
      "Epoch 53/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 27ms/step - loss: 0.4160 - mse: 0.4160 - val_loss: 0.5351 - val_mse: 0.5351\n",
      "Epoch 54/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 24ms/step - loss: 0.4156 - mse: 0.4156 - val_loss: 0.5330 - val_mse: 0.5330\n",
      "Epoch 55/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 16ms/step - loss: 0.4153 - mse: 0.4153 - val_loss: 0.5320 - val_mse: 0.5320\n",
      "Epoch 56/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 16ms/step - loss: 0.4152 - mse: 0.4152 - val_loss: 0.5349 - val_mse: 0.5349\n",
      "Epoch 57/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 18ms/step - loss: 0.4149 - mse: 0.4149 - val_loss: 0.5354 - val_mse: 0.5354\n",
      "Epoch 58/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 0.4146 - mse: 0.4146 - val_loss: 0.5380 - val_mse: 0.5380\n",
      "Epoch 59/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 30ms/step - loss: 0.4146 - mse: 0.4146 - val_loss: 0.5354 - val_mse: 0.5354\n",
      "Epoch 60/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 37ms/step - loss: 0.4142 - mse: 0.4142 - val_loss: 0.5385 - val_mse: 0.5385\n",
      "Epoch 61/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 46ms/step - loss: 0.4136 - mse: 0.4136 - val_loss: 0.5379 - val_mse: 0.5379\n",
      "Epoch 62/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 31ms/step - loss: 0.4138 - mse: 0.4138 - val_loss: 0.5374 - val_mse: 0.5374\n",
      "Epoch 63/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 18ms/step - loss: 0.4133 - mse: 0.4133 - val_loss: 0.5416 - val_mse: 0.5416\n",
      "Epoch 64/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 14ms/step - loss: 0.4133 - mse: 0.4133 - val_loss: 0.5403 - val_mse: 0.5403\n",
      "Epoch 65/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 12ms/step - loss: 0.4130 - mse: 0.4130 - val_loss: 0.5428 - val_mse: 0.5428\n",
      "Epoch 66/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 25ms/step - loss: 0.4126 - mse: 0.4126 - val_loss: 0.5446 - val_mse: 0.5446\n",
      "Epoch 67/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 13ms/step - loss: 0.4122 - mse: 0.4122 - val_loss: 0.5435 - val_mse: 0.5435\n",
      "Epoch 68/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 24ms/step - loss: 0.4122 - mse: 0.4122 - val_loss: 0.5480 - val_mse: 0.5480\n",
      "Epoch 69/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 16ms/step - loss: 0.4122 - mse: 0.4122 - val_loss: 0.5401 - val_mse: 0.5401\n",
      "Epoch 70/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 16ms/step - loss: 0.4118 - mse: 0.4118 - val_loss: 0.5433 - val_mse: 0.5433\n",
      "Epoch 71/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 15ms/step - loss: 0.4115 - mse: 0.4115 - val_loss: 0.5469 - val_mse: 0.5469\n",
      "Epoch 72/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 25ms/step - loss: 0.4113 - mse: 0.4113 - val_loss: 0.5434 - val_mse: 0.5434\n",
      "Epoch 73/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 23ms/step - loss: 0.4111 - mse: 0.4111 - val_loss: 0.5442 - val_mse: 0.5442\n",
      "Epoch 74/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 23ms/step - loss: 0.4110 - mse: 0.4110 - val_loss: 0.5394 - val_mse: 0.5394\n",
      "Epoch 75/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 17ms/step - loss: 0.4108 - mse: 0.4108 - val_loss: 0.5407 - val_mse: 0.5407\n",
      "Epoch 76/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 11ms/step - loss: 0.4107 - mse: 0.4107 - val_loss: 0.5412 - val_mse: 0.5412\n",
      "Epoch 77/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 13ms/step - loss: 0.4106 - mse: 0.4106 - val_loss: 0.5442 - val_mse: 0.5442\n",
      "Epoch 78/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 16ms/step - loss: 0.4103 - mse: 0.4103 - val_loss: 0.5438 - val_mse: 0.5438\n",
      "Epoch 79/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 18ms/step - loss: 0.4102 - mse: 0.4102 - val_loss: 0.5403 - val_mse: 0.5403\n",
      "Epoch 80/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 14ms/step - loss: 0.4099 - mse: 0.4099 - val_loss: 0.5424 - val_mse: 0.5424\n",
      "Epoch 81/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 13ms/step - loss: 0.4097 - mse: 0.4097 - val_loss: 0.5455 - val_mse: 0.5455\n",
      "Epoch 82/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 11ms/step - loss: 0.4097 - mse: 0.4097 - val_loss: 0.5462 - val_mse: 0.5462\n",
      "Epoch 83/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 16ms/step - loss: 0.4095 - mse: 0.4095 - val_loss: 0.5505 - val_mse: 0.5505\n",
      "Epoch 84/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 17ms/step - loss: 0.4092 - mse: 0.4092 - val_loss: 0.5500 - val_mse: 0.5500\n",
      "Epoch 85/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 21ms/step - loss: 0.4094 - mse: 0.4094 - val_loss: 0.5514 - val_mse: 0.5514\n",
      "Epoch 86/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 13ms/step - loss: 0.4091 - mse: 0.4091 - val_loss: 0.5554 - val_mse: 0.5554\n",
      "Epoch 87/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 37ms/step - loss: 0.4089 - mse: 0.4089 - val_loss: 0.5425 - val_mse: 0.5425\n",
      "Epoch 88/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 23ms/step - loss: 0.4087 - mse: 0.4087 - val_loss: 0.5467 - val_mse: 0.5467\n",
      "Epoch 89/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 24ms/step - loss: 0.4086 - mse: 0.4086 - val_loss: 0.5488 - val_mse: 0.5488\n",
      "Epoch 90/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 26ms/step - loss: 0.4085 - mse: 0.4085 - val_loss: 0.5457 - val_mse: 0.5457\n",
      "Epoch 91/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 19ms/step - loss: 0.4083 - mse: 0.4083 - val_loss: 0.5501 - val_mse: 0.5501\n",
      "Epoch 92/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 17ms/step - loss: 0.4083 - mse: 0.4083 - val_loss: 0.5481 - val_mse: 0.5481\n",
      "Epoch 93/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 13ms/step - loss: 0.4082 - mse: 0.4082 - val_loss: 0.5476 - val_mse: 0.5476\n",
      "Epoch 94/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 13ms/step - loss: 0.4079 - mse: 0.4079 - val_loss: 0.5532 - val_mse: 0.5532\n",
      "Epoch 95/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 11ms/step - loss: 0.4078 - mse: 0.4078 - val_loss: 0.5493 - val_mse: 0.5493\n",
      "Epoch 96/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 12ms/step - loss: 0.4077 - mse: 0.4077 - val_loss: 0.5485 - val_mse: 0.5485\n",
      "Epoch 97/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 20ms/step - loss: 0.4075 - mse: 0.4075 - val_loss: 0.5537 - val_mse: 0.5537\n",
      "Epoch 98/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 14ms/step - loss: 0.4076 - mse: 0.4076 - val_loss: 0.5495 - val_mse: 0.5495\n",
      "Epoch 99/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 14ms/step - loss: 0.4073 - mse: 0.4073 - val_loss: 0.5494 - val_mse: 0.5494\n",
      "Epoch 100/100\n",
      "\u001b[1m7975/7975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 13ms/step - loss: 0.4071 - mse: 0.4071 - val_loss: 0.5575 - val_mse: 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assume X, y are your features and multi-target docking scores numpy arrays\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "x = Dense(128, activation='relu')(input_layer)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_layer = Dense(y.shape[1], activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mse'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"../models/docking_score_prediction_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     34\u001b[0m protein_columns \u001b[39m=\u001b[39m [\n\u001b[0;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBinding_affinity_3ebh\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBinding_affinity_3i65\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBinding_affinity_8em8\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     38\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBinding_affinity_9nsr\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     39\u001b[0m ]\n\u001b[0;32m     41\u001b[0m \u001b[39m# Predict on validation data\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m     44\u001b[0m \u001b[39m# Evaluate\u001b[39;00m\n\u001b[0;32m     45\u001b[0m evaluate_model_performance(y_val, y_pred, protein_columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model_performance(y_true, y_pred, protein_columns):\n",
    "    for i, col_name in enumerate(protein_columns):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        print(f\"Metrics for {col_name}:\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE : {mae:.4f}\")\n",
    "        print(f\"  R²  : {r2:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "        # Plot true vs predicted\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.scatter(y_true[:, i], y_pred[:, i], alpha=0.5)\n",
    "        lims = [min(y_true[:, i].min(), y_pred[:, i].min()),\n",
    "                max(y_true[:, i].max(), y_pred[:, i].max())]\n",
    "        plt.plot(lims, lims, 'r--')\n",
    "        plt.xlabel('True Docking Score')\n",
    "        plt.ylabel('Predicted Docking Score')\n",
    "        plt.title(f'{col_name} - Predicted vs True')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# y_val - your true docking score matrix (num_samples x num_proteins)\n",
    "# model - your trained Keras/TensorFlow model\n",
    "# X_val - your validation features matrix\n",
    "\n",
    "# Your exact docking score column names\n",
    "protein_columns = [\n",
    "    'Binding_affinity_3ebh',\n",
    "    'Binding_affinity_3i65',\n",
    "    'Binding_affinity_8em8',\n",
    "    'Binding_affinity_9nsr'\n",
    "]\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model_performance(y_val, y_pred, protein_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.9)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# docking score columns\n",
    "protein_columns = [\n",
    "    'Binding_affinity_3ebh',\n",
    "    'Binding_affinity_3i65',\n",
    "    'Binding_affinity_8em8',\n",
    "    'Binding_affinity_9nsr'\n",
    "]\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Define base regressor and wrap in MultiOutputRegressor\n",
    "base_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "multi_rf = MultiOutputRegressor(base_rf)\n",
    "\n",
    "# 2. Train model\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# 3. Save each underlying model separately\n",
    "for i, model in enumerate(multi_rf.estimators_):\n",
    "    filename = '../models/f\"rf_{protein_columns[i]}.joblib\"'\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Saved model for {protein_columns[i]} at {filename}\")\n",
    "\n",
    "# 4. Evaluate on validation set\n",
    "y_pred = multi_rf.predict(X_val)\n",
    "\n",
    "def evaluate_model_performance(y_true, y_pred, protein_columns):\n",
    "    for i, col_name in enumerate(protein_columns):\n",
    "        mse = mean_squared_error(y_true[:, i], y_pred[:, i])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "        print(f\"Metrics for {col_name}:\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE : {mae:.4f}\")\n",
    "        print(f\"  R²  : {r2:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "        # Scatter plot true vs predicted\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.scatter(y_true[:, i], y_pred[:, i], alpha=0.6)\n",
    "        lims = [min(y_true[:, i].min(), y_pred[:, i].min()),\n",
    "                max(y_true[:, i].max(), y_pred[:, i].max())]\n",
    "        plt.plot(lims, lims, 'r--')\n",
    "        plt.xlabel('True Docking Score')\n",
    "        plt.ylabel('Predicted Docking Score')\n",
    "        plt.title(f'{col_name} - Predicted vs True')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "evaluate_model_performance(y_val, y_pred, protein_columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
